---
title: 'ESC530 Analysing Spatial Data: Project Report'
author: "Sebastian Luckeneder"
date: "15/12/2020"
output:
  html_document: default
  pdf_document: default
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=12, fig.height=8)
```

# Mining and regional GDP growth - the Brazilian case 

## Research interest (beyond this course project)

It is well-known that mining activities relate to hazardous environmental and social consequences. And yet, mining is often related to 'development' as a constitutional starting point of a series of economic and social changes. This proposed study deals with development in the sense of regional GDP growth (and I am aware that development goes beyond GDP growth), asking whether mining activities relate to the local GDP of mining municipalities and their surroundings. 

The effects of mining on the economy have been widely debated, and theoretical channels have been discussed, from which we can draw ambiguous conclusions. On the one hand, there is the concept of 'mining clusters', which is centred on the idea that linkages between multinational corporations and local firms, local employment creation and knowledge spillovers are drivers of regional development [@arias2014]. On the other hand, the emergence of 'enclave economies' seems just as reasonable, because rather than being related to the creation of local employment, the large-scale natural resource development in the mining sector is highly capital-intensive. It requires significant funds for exploration, energy infrastructure, machinery, transportation networks and construction [@emel2008risky]. Also, mining increasingly becomes technologically intensive [@humphreys2007introduction]. Therefore, it is likely that employment for low-skilled workers is only short-term during the construction phase, while mining in the long-run offers fewer positions, which are taken by high-skilled (and potentially foreign) employees [@arias2014]. Furthermore, capital-intensive resources are associated with a higher likelihood of civil conflict than labour-intensive resources (such as biomass) [@van2011natural], which might hinder economic growth. 

My study will concentrate on mining expansion in Brazil. The country's president, Jair Bolsonaro, is currently on the verge of opening peripheral indigenous and protected land for mining [@siqueira2020proposed]. He constructs an old fashioned development narrative, which accepts the destruction of ecosystems, most importantly the Brazilian Amazon, and the extinction of indigenous populations, in the name of development [@hope2019brazilian]. While it is evident that the policy path taken here will threaten people and unique ecosystems  [@siqueira2020proposed; @rorato2020brazilian], there is no clear empirical evidence if these extractive activities will foster local economic growth. Such a link is, however, crucial to the president's line of argumentation, stating that environmental degradation and the destruction of indigenous livelihoods were simply the costs of such a development, from which also local communities would benefit [@branford2019brazil]. My research question is therefore, whether mining acivities in Brazil can be related to the growth of local, i.e. municipality-level, GDP.

Insights from the talk with Paolo: Paragraph on the two worlds of mining in Brazil: large-scale and artisanal mining. Minas Gerais vs. opening indigenous land. Ambiguity also how indigenous communities deal with it. 

I will focus on 2002 - 2011 growth period

I want to challenge the claim that mining positively affects both mining regions and, via spillover effects, their neighbours in terms of economic growth. For that, I intend employing a spatial econometric growth model as motivated by @lesage2008growth. Such an empirical framework will enable relating detailed mine-specific data on extraction intensity to regional economic impacts. It will take spatial autocorrelation into consideration and will allow the estimation of spillover effects between municipalities.

## Exploring the data

First, for getting a clearer picture about the spatial relations of the variables of interest, I assess how mining operations, GDP growth rates, and potentially important explanatory variables are distributed across Brazil.

As the basis for all maps, I access shapefiles from the Brazilian Institute of Geography and Statistics [@ibge2020] for national borders, states, and municipalities. I utilised the `geobr` package, selected the year 2001 (because there are no maps available for 2002) and transformed the coordinate reference system to WGS84:

```{r base, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
library(dplyr)
library(tidyr)
library(sf)

library(geobr)
print(geobr::list_geobr(), n = 5)

yr <- 2001

if(!file.exists(paste0("ibge_data/geobr/base_nat_", yr, ".shp"))){
  base_nat <- geobr::read_country(year = yr, simplified = FALSE, showProgress = TRUE) 
  sf::st_write(base_nat, paste0("ibge_data/geobr/base_nat_", yr, ".shp"))
} else {
  base_nat <- sf::read_sf("ibge_data/geobr/base_nat_2001.shp")
}

if(!file.exists(paste0("ibge_data/geobr/base_sta_", yr, ".shp"))){
  base_sta <- geobr::read_state(year = yr, simplified = FALSE, showProgress = TRUE)
  sf::st_write(base_sta, paste0("ibge_data/geobr/base_sta_", yr, ".shp"))
} else {
  base_sta <- sf::read_sf("ibge_data/geobr/base_sta_2001.shp")
}

if(!file.exists(paste0("ibge_data/geobr/base_mun_", yr, ".shp"))){
  base_mun <- geobr::read_municipality(code_mn = "all",year = yr, simplified = FALSE, showProgress = TRUE) 
  sf::st_write(base_mun, paste0("ibge_data/geobr/base_mun_", yr, ".shp"))
} else {
  base_mun <- sf::read_sf("ibge_data/geobr/base_mun_2001.shp")
}

base_nat <- base_nat %>% sf::st_transform(crs = sf::st_crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
base_sta <- base_sta %>% sf::st_transform(crs = sf::st_crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))
base_mun <- base_mun %>% dplyr::mutate(code_mn = as.character(code_mn)) %>%
  sf::st_transform(crs = sf::st_crs("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs"))

```

### Mine locations

The locations of mining sites can be obtained from S&P's SNL Metals and Mining Database [@snl2020]. This database is not freely available and there are clear copyright restrictions by SNL. Therefore, I pre-calculated the number of active mines within each municipality (using `sf::st_join(., join = "st_intersects")` for merging the point data of mine locations with the municipality polygons and then grouping and summarising by municipality ID) and directly access this ready-to-use data:

```{r mines, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
bra_mines <- sf::read_sf("mine_data/bra_mines.shp")
```

Let's draw a map:

```{r p.mines, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
library(tmap)

bra_mines <- bra_mines %>%
  dplyr::mutate(mine_count = ifelse(mine_count == 0, NA, mine_count))

regs <- c("MG", "AC", "AM", "RO", "RR", "AP", "PA", "TO", "MT")

tmap::tm_shape(bra_mines) + 
  tmap::tm_borders(lwd=0.5, alpha=0.4) +
  tmap::tm_fill(col = "mine_count", style = "pretty", as.count = TRUE, 
                colorNA = "white", textNA = "0",
                palette = "-viridis",
                title = "No. of active mines (n = 299)", legend.reverse = TRUE) +
tmap::tm_shape(base_sta %>% dplyr::filter(abbrv_s %in% regs)) +
  tmap::tm_borders(lwd=1) +
tmap::tm_shape(base_nat) +
  tmap::tm_borders(lwd=2) +
tmap::tm_layout(legend.position = c("left", "bottom"))
```

Move to paragraph on the two worlds of mining in Brazil: large-scale and artisanal mining. Minas Gerais vs. opening indigenous land. Ambiguity also how indigenous communities deal with it. Zoom into MG and north + overlap with protected areas

```{r pa, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
wdpa_bra <- sf::read_sf("wdpa_data/wdpa_bra.shp")
```

```{r pminesmg, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
library(stringr)

# Minas Gerais
regs <- c("MG")
regs_wdpa <- stringr::str_subset(unique(wdpa_bra$SUB_LOC), paste(regs, collapse = "|"))

# union for nicer plots, export because st_union takes time
if (! file.exists("wdpa_data/wdpa_bra_clean_MG_indig.shp")){
  wdpa_bra_clean_MG_indig <- wdpa_bra %>% dplyr::filter(SUB_LOC %in% regs_wdpa & TYPE == "Indigenous") %>% sf::st_union()
  wdpa_bra_clean_MG_other <- wdpa_bra %>% dplyr::filter(SUB_LOC %in% regs_wdpa & TYPE == "other") %>% sf::st_union()
  sf::st_write(wdpa_bra_clean_MG_indig, dsn = "wdpa_data/wdpa_bra_clean_MG_indig.shp", delete_dsn = TRUE)
  sf::st_write(wdpa_bra_clean_MG_other, dsn = "wdpa_data/wdpa_bra_clean_MG_other.shp", delete_dsn = TRUE)
} else {
  wdpa_bra_clean_MG_indig <- sf::read_sf("wdpa_data/wdpa_bra_clean_MG_indig.shp")
  wdpa_bra_clean_MG_other <- sf::read_sf("wdpa_data/wdpa_bra_clean_MG_other.shp")
}

wdpa_bra_clean_MG <- rbind(wdpa_bra_clean_MG_indig %>% dplyr::mutate("TYPE" = "Indigenous"), 
                           wdpa_bra_clean_MG_other %>% dplyr::mutate("TYPE" = "Other"))

tmap::tm_shape(bra_mines %>% dplyr::filter(abbrv_s %in% regs)) + 
  tmap::tm_borders(lwd=0.5, alpha=0.4) +
  tmap::tm_fill(col = "mine_count", n = 4, style = "pretty", as.count = TRUE, 
                colorNA = "white", textNA = "0",
                palette = "-viridis",
                title = "No. of active mines (n = 96)", legend.reverse = TRUE) +
tmap::tm_shape(wdpa_bra_clean_MG) +
  tmap::tm_fill(col = "TYPE", palette = c("red", "darkgrey"), alpha=0.25, title = "Protected area") +
tmap::tm_shape(base_sta %>% dplyr::filter(abbrv_s %in% regs)) +
  tmap::tm_borders(lwd=2) +
tmap::tm_layout(main.title = "Minas Gerais", legend.position = c("left", "top")) + 
tmap::tm_scale_bar(position=c("right", "bottom"))
```

```{r pminesnorth, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
# North Region + Mato Grosso
regs <- c("AC", "AM", "RO", "RR", "AP", "PA", "TO", "MT")
regs_wdpa <- str_subset(unique(wdpa_bra$SUB_LOC), paste(regs, collapse = "|"))

# union for nicer plots because some areas overlap, store because st_union takes time
if (! file.exists("wdpa_data/wdpa_bra_clean_north_indig.shp")){
  wdpa_bra_clean_north_indig <- wdpa_bra %>% dplyr::filter(SUB_LOC %in% regs_wdpa & TYPE == "Indigenous") %>% sf::st_union()
  wdpa_bra_clean_north_other <- wdpa_bra %>% dplyr::filter(SUB_LOC %in% regs_wdpa & TYPE == "other") %>% sf::st_union()
  sf::st_write(wdpa_bra_clean_north_indig, dsn = "wdpa_data/wdpa_bra_clean_north_indig.shp", delete_dsn = TRUE)
  sf::st_write(wdpa_bra_clean_north_other, dsn = "wdpa_data/wdpa_bra_clean_north_other.shp", delete_dsn = TRUE)
} else {
  wdpa_bra_clean_north_indig <- sf::read_sf("wdpa_data/wdpa_bra_clean_north_indig.shp")
  wdpa_bra_clean_north_other <- sf::read_sf("wdpa_data/wdpa_bra_clean_north_other.shp")
}

wdpa_bra_clean_north <- rbind(wdpa_bra_clean_north_indig %>% dplyr::mutate("TYPE" = "Indigenous"), 
                           wdpa_bra_clean_north_other %>% dplyr::mutate("TYPE" = "Other"))

tmap::tm_shape(bra_mines %>% dplyr::filter(abbrv_s %in% regs)) + 
  tmap::tm_borders(lwd=0.5, alpha=0.4) +
  tmap::tm_fill(col = "mine_count", n = 4, style = "pretty", as.count = TRUE, 
                colorNA = "white", textNA = "0", palette = "-viridis",
                title = "No. of active \nmines (n = 103)", legend.reverse = TRUE) +
tmap::tm_shape(wdpa_bra_clean_north) +
  tmap::tm_fill(col = "TYPE", palette = c("red", "darkgrey"), alpha=0.25, title = "Protected area") +
tmap::tm_shape(base_sta %>% dplyr::filter(abbrv_s %in% regs)) +
  tmap::tm_borders(lwd=2) +
tmap::tm_layout(main.title = "North Region and Mato Grosso", legend.position = c("left", "bottom"), legend.stack = "horizontal") + 
tmap::tm_scale_bar(position=c("right", "bottom"))
```

### Municipality statistics

Socio-economic data at the municipality-level can be accessed from the Brazilian Institute of Geography and Statistics [@ibge2020]. Since I am interested in the 2002-2011 growth period, I will need to assess 2002 and 2011 data. Due to a number of changes of political borders and entities in the past, I have to drop observations that were affected by a change of borders during the time period covered. (In fact, this can be improved, but it would require more data wrangling than feasible within the scope of the project.) 

#### GDP and growth rates

Millenium started with high growth rates. Per capita GDP rose from 2.800 USD in 2002 to 13.200 USD in 2011 (that's about 370%!). Economic crisis since 2014. 
BRL stable since currency crises in the 1990s, but compared to EUR or USD at high inflation rates (5-10%). This partly explains the low 2002 numbers.
Insert a chart


IBGE Data, 
GDP per capita 2002
per capita growth 2002-2011

```{r gdpdat, echo = FALSE, eval = TRUE, message=FALSE,  warning=FALSE}
dat_ibge_1 <- readxl::read_excel("ibge_data/gdp_munip_1999-2012.xlsx")
colnames(dat_ibge_1) <- c("ano", 
"codigo_uf", "nome_uf",
"cod_municipio", "nome_munic", "nome_metro",
"codigo_meso", "nome_meso", "codigo_micro", "nome_micro",
"vab_agropecuaria", "vab_industria", 
"vab_servicos_exclusivo", "vab_adm_publica", 
"impostos", "pib_total",
"pop_last", "pib_per_capita_last")
dat_ibge_1 <- dat_ibge_1 %>%
  dplyr::filter(ano < 2010) %>%
  dplyr::mutate(cod_municipio = as.character(cod_municipio),
                ano = as.numeric(ano)) 
dat_ibge_pop <- read.csv("ibge_data/pop_municip_2002_2011.csv")
dat_ibge_1 <- dat_ibge_1 %>% dplyr::mutate(unid = paste0(ano, cod_municipio)) %>%
  dplyr::left_join(dat_ibge_pop %>% dplyr::mutate(unid = paste0(ano, cod_municipio)) %>% dplyr::select(unid, pop), by = "unid") %>%
  dplyr::mutate(pib_per_capita = pib_total * 1000 / pop)

dat_ibge_2 <- readxl::read_excel("ibge_data/gdp_munip_2010-2017.xls")
colnames(dat_ibge_2) <- c("ano", "codigo_regiao", "nome_regiao",
"codigo_uf", "sigla_uf", "nome_uf",
"cod_municipio", "nome_munic", "nome_metro",
"codigo_meso", "nome_meso", "codigo_micro", "nome_micro",
"codigo_reg_geo_imediata", "nome_reg_geo_imediata", "mun_reg_geo_imediata",
"codigo_reg_geo_intermediaria", "nome_reg_geo_intermediaria", "mun_reg_geo_intermediaria",
"codigo_concentracao_urbana", "nome_concentracao_urbana", "tipo_concentracao_urbana",
"codigo_arranjo_populacional", "nome_arranjo_populacional",
"hierarquia_urbana", "hierarquia_urbana_principais",
"codigo_regiao_rural", "nome_regiao_rural", "regiao_rural_classificacao",
"amazonia_legal", "semiarido", "cidade_de_sao_paulo",
"vab_agropecuaria", "vab_industria", "vab_servicos_exclusivo", "vab_adm_publica", "vab_total",
"impostos", "pib_total",
"pib_per_capita",
"atividade_vab1", "atividade_vab2", "atividade_vab3")
dat_ibge_2 <- dat_ibge_2 %>%
  dplyr::mutate(cod_municipio = as.character(cod_municipio),
                codigo_meso = as.character(codigo_meso),
                codigo_micro = as.character(codigo_micro)) %>%
  dplyr::mutate(pop =  pib_total * 1000 / pib_per_capita)

dat_ibge <- dplyr::bind_rows(dat_ibge_1, dat_ibge_2)
```

```{r gdpmap, echo = FALSE, eval = TRUE, message=FALSE,  warning=FALSE}
dat_gdp <- dat_ibge %>% dplyr::filter(ano == 2002) %>% 
  dplyr::mutate(pib_total = pib_total / 1000)

dat_gdp <- base_mun %>% dplyr::left_join(dat_gdp, by = c("code_mn" = "cod_municipio"))

# dat_growth <- dat_ibge %>% dplyr::filter(ano %in% c(2002, 2011)) %>% 
#   dplyr::select(cod_municipio, ano, pib_total) %>%
#   tidyr::spread(key = "ano", value = "pib_total") %>%
#   dplyr::mutate(g = (`2011` - `2002`) / `2002` * 100) %>%
#   dplyr::select(cod_municipio, g)
dat_growth <- dat_ibge %>% dplyr::filter(ano %in% c(2002, 2011)) %>% 
  dplyr::select(cod_municipio, ano, pib_per_capita) %>%
  tidyr::spread(key = "ano", value = "pib_per_capita") %>%
  dplyr::mutate(g_cap = (`2011` - `2002`) / `2002` * 100) %>%
  dplyr::select(cod_municipio, g_cap)

dat_gdp <- dat_gdp %>% 
  dplyr::left_join(dat_growth, by = c("code_mn" = "cod_municipio"))

tmap::tm_shape(dat_gdp) + 
  tmap::tm_facets(nrow = 1) + 
  tmap::tm_borders(lwd=0.5, alpha=0.4) + 
  tmap::tm_fill(col = c("pib_total", "g_cap"), n=8, style="quantile", palette = "-magma", title = "") +
  tmap::tm_layout(legend.position = c("left", "bottom"),
                  panel.labels=c("2002 per capita GDP (current BRL)", "2002-2011 growth rate (%)"))
```


HDI is not available at municipality level

#### Population and growth rates

```{r popmap, echo = FALSE, eval = TRUE, message=FALSE,  warning=FALSE}
dat_pop <- dat_ibge %>% dplyr::filter(ano == 2002)
dat_pop <- base_mun %>% dplyr::left_join(dat_pop, by = c("code_mn" = "cod_municipio"))

dat_popgrowth <- dat_ibge %>% dplyr::filter(ano %in% c(2002, 2011)) %>% 
  dplyr::select(cod_municipio, ano, pop) %>%
  tidyr::spread(key = "ano", value = "pop") %>%
  dplyr::mutate(g_pop = (`2011` - `2002`) / `2002` * 100) %>%
  dplyr::select(cod_municipio, g_pop)

dat_pop <- dat_pop %>% 
  dplyr::left_join(dat_popgrowth, by = c("code_mn" = "cod_municipio"))

tmap::tm_shape(dat_pop) + 
  tmap::tm_facets(nrow = 1) + 
  tmap::tm_borders(lwd=0.5, alpha=0.4) + 
  tmap::tm_fill(col = c("pop", "g_pop"), n=8, style="quantile", title = "") +
  tmap::tm_layout(legend.position = c("left", "bottom"),
                  panel.labels=c("2002 population", "2002-2011 population growth"))
```

#### Sectoral structure

```{r sectormap, echo = FALSE, eval = TRUE, message=FALSE,  warning=FALSE}
dat_sect <- dat_ibge %>% dplyr::filter(ano == 2002) %>% 
  dplyr::mutate(cod_municipio = as.character(cod_municipio)) %>% 
  dplyr::mutate(vab_agropecuaria = ifelse(vab_agropecuaria < 0, 0, vab_agropecuaria)) %>%
  dplyr::mutate(vab_total = vab_agropecuaria + vab_industria + vab_servicos_exclusivo + vab_adm_publica) %>%
  dplyr::mutate(vab_agropecuaria_perc = vab_agropecuaria / vab_total,
                vab_industria_perc = vab_industria / vab_total,
                vab_servicos_exclusivo_perc = vab_servicos_exclusivo / vab_total,
                vab_adm_publica_perc = vab_adm_publica / vab_total)

dat_sect <- base_mun %>% dplyr::left_join(dat_sect, by = c("code_mn" = "cod_municipio"))

tmap::tm_shape(dat_sect) + 
  tmap::tm_facets(nrow = 2) + 
  tmap::tm_borders(lwd=0.5, alpha=0.4) + 
  tmap::tm_fill(col = c("vab_agropecuaria_perc", "vab_industria_perc", "vab_servicos_exclusivo_perc", "vab_adm_publica_perc"), 
                n=8, style="quantile", title = "", palette = "-magma") +
  tmap::tm_layout(legend.position = c("left", "bottom"),
                  panel.labels=c("2002 GVA acgriculture (%)", "2002 GVA industry (%)", "2002 GVA services (%)", "2002 GVA public sector (%)"))
```

#### Open issues

Mine data: observations of the current, endogeneity? For causal statements we would certainly need date of mine opening

Huge (!) growth rates  -> outliers

Employment and human capital

panel setting y/n?


## Spatial connectivity

Use functions in spdep to define neighbours and then test for global and local spatial autocorrelation

### W

W is important for imposing spatial structure in a parsimonious way.

Some variations: contiguity, 5 nearest, distance bound

Decreasing functions of distance: heavy, bad for modelling later on

Lets start with queen contiguity, where neighbourhodd is defined by sharing borders + interpretation

```{r neighbourscheck, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
library(spdep)
nb_q <- spdep::poly2nb(base_mun, queen=TRUE)
summary(nb_q)
```

The average number of neighbors (adjacent polygons) is 5.9, 9 polygons have only 1 neighbor and the most connected municipality borders 23 neighbors. 2 municipalities are islands and hence, according to this definition, have no neighbours. Since ..., I exclude them from the data.

```{r neighboursq, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
base_mun <- base_mun[-c(1523, 3496),]
nb_q <- spdep::poly2nb(base_mun, queen=TRUE)

plot(sf::st_geometry(base_mun), border="grey", lwd=0.5)
coords <- sf::st_centroid(sf::st_geometry(base_mun), of_largest_polygon=TRUE)
plot(nb_q, coords=st_coordinates(coords), add=TRUE, points=FALSE, lwd=0.5)
```

Alternatively: k = 5 nearest neighbours using `spdep::knearneigh` + interpretation

```{r neighboursn, echo = FALSE, eval = TRUE, message=FALSE,  warning=FALSE}
nb_5nnb <- spdep::knearneigh(coords, k=5)
nb_5nnb <- spdep::knn2nb(nb_5nnb, sym=F)
plot(sf::st_geometry(base_mun), border="grey", lwd=0.5)
plot(nb_5nnb, coords=st_coordinates(coords), add=TRUE, points=FALSE, lwd=0.5)
```

Another option: distance bound, where I make sure that each municipality has at least 1 neighbour using `spdep::knearneigh(k=1)` first and extracting maximum distance, followed by `spdep::dnearneigh` using this distance as the upper bound. Interpretation: this is not so good.

```{r neighboursd, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
nb_1nnb <- spdep::knearneigh(coords, k=1)
nb_1nnb <- spdep::knn2nb(nb_1nnb, sym=F)
maxdist <- max(unlist(spdep::nbdists(nb_1nnb, coords=coords)))

nb_dist <- spdep::dnearneigh(coords, d1=0, d2=maxdist)
plot(sf::st_geometry(base_mun), border="grey", lwd=0.5)
plot(nb_dist, coords=st_coordinates(coords), add=TRUE, points=FALSE, lwd=0.5)
```

Therefore, I will continue with k=5 nnb. Queen contiguity and other k can be used for robustness checks at a later stage.

A note on dimension: weights and observations must fit. Exclude NA entries (2) from the data (which already excludes islands) and re-calculate weights.

```{r dims, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}

dat_gdp <- dat_gdp[!is.na(dat_gdp$pib_per_capita),]
dat_sect <- dat_sect %>% dplyr::filter(code_mn %in% dat_gdp$code_mn)
dat_pop <- dat_pop %>% dplyr::filter(code_mn %in% dat_gdp$code_mn)

coords <- sf::st_centroid(sf::st_geometry(dat_gdp), of_largest_polygon=TRUE)
nb_5nnb <- spdep::knearneigh(coords, k=5)
nb_5nnb <- spdep::knn2nb(nb_5nnb, sym=F)

```

### Spatial autocorrelation

Some sentences on spatial AC: What is it, why is it important?

Positive spatial AC means that similar observations are closer to each other. Negative spatial AC close observations have more dissimilar values than those locations further away

In a regression framework...

From examining the maps above, we can already guess that clustering is going on. But we also want to test. Most common measure for global (i.e. providing a single value representing the data) spatial autocorellation is the Moran's I statistic. It essentially evaluates how similar observations at location i deviate from the mean compared to neighbouring regions of that location i compare to the mean. Formally, it is defined as

$$I = \frac{\sum_{i=1}^n\sum_{j=1}^n w_{i,j} (x_i-\bar{x}) (x_j-\bar{x})}{(\sum_{i=1}^n\sum_{j=1}^n w_{i,j}) \sum_{i=1}^n(x_i-\bar{x})^2}$$

where $x_i$ and $x_j$ are observations at locations i and j, and $w_i,j$ is the weight that determines the relationship between i and j. We can derive the expected value of I, which would correspond to a random distributions of observations

$$E(I) = \frac{-1}{n-1}$$
and test whether I is significantly different from E(I).

For determining which observations are neighbours, we make use of our above defined definition of neighbourhood
row standardisation style="W"

```{r moransi, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
lwW <- spdep::nb2listw(nb_5nnb, style="W")

out <- dplyr::bind_rows(
  broom::tidy(spdep::moran.test(dat_gdp$pib_per_capita, listw=lwW, randomisation=FALSE, alternative="two.sided"))[1:5],
  broom::tidy(spdep::moran.test(dat_gdp$g_cap, listw=lwW, randomisation=FALSE, alternative="two.sided"))[1:5],
  broom::tidy(spdep::moran.test(dat_pop$g_pop, listw=lwW, randomisation=FALSE, alternative="two.sided"))[1:5],
  broom::tidy(spdep::moran.test(dat_sect$vab_agropecuaria_perc, listw=lwW, randomisation=FALSE, alternative="two.sided"))[1:5],
  broom::tidy(spdep::moran.test(dat_sect$vab_industria_perc, listw=lwW, randomisation=FALSE, alternative="two.sided"))[1:5],
  broom::tidy(spdep::moran.test(dat_sect$vab_servicos_exclusivo_perc, listw=lwW, randomisation=FALSE, alternative="two.sided"))[1:5],
  broom::tidy(spdep::moran.test(dat_sect$vab_adm_publica_perc, listw=lwW, randomisation=FALSE, alternative="two.sided"))[1:5])
names(out)[1:3] <- c("Moran's I", "Expectation", "Variance")
out <- dplyr::bind_cols("Variable" = c("2002 GDP (per capita, BRL)", "2002-2011 per cap. GDP growth (%)", "2002-2011 population growth (%)", 
                                       "2002 GVA acgriculture (%)", "2002 GVA industry (%)", "2002 GVA services (%)", "2002 GVA public sector (%)"), out); out
```

```{r moranplots, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE, fig.show="hold", out.width="50%"}
spdep::moran.plot(dat_gdp$pib_per_capita, listw=lwW)
spdep::moran.plot(dat_gdp$g_cap, listw=lwW)
```

While the strength of this global statistic is that is summarises the data with a single value, it does not give any insights which observations are similar or different to observations in their neighbourhodd. Here, the Local Moran's I can help. Its nature is similar to the global statistic, but each observation receives its own I statistic, as well as its own expected value and variance. Without going into detail here, it essentially evaluates how each observation deviates from the mean compared to how its neighbouring observations compare to the mean. 

```{r localmoran, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
localm_pib <- spdep::localmoran(dat_gdp$pib_per_capita, listw=lwW, alternative = "two.sided") %>% dplyr::as_data_frame() 
colnames(localm_pib) <- c(colnames(localm_pib)[-5], "p_pib")
localm_pib <- sf::st_as_sf(localm_pib %>% 
                             dplyr::mutate(geometry = sf::st_geometry(dat_gdp)) %>%
                             dplyr::mutate(code_mn = dat_gdp$code_mn)) %>% 
  dplyr::mutate(lsa_pib = ifelse(Ii > 0, "positive", "negative"))

localm_g <- spdep::localmoran(dat_gdp$g_cap, listw=lwW, alternative = "two.sided") %>% dplyr::as_data_frame() 
colnames(localm_g) <- c(colnames(localm_g)[-5], "p_g")
localm_g <- localm_g %>% dplyr::mutate(code_mn = dat_gdp$code_mn) %>%
  dplyr::mutate(lsa_g = ifelse(Ii > 0, "positive", "negative"))

localm <- dplyr::left_join(localm_pib, localm_g, by = "code_mn") %>%
  dplyr::mutate(lsa_pib = ifelse(p_pib < 0.05, lsa_pib, NA),
                lsa_g = ifelse(p_g < 0.05, lsa_g, NA)) 

tmap::tm_shape(base_nat) +
  tmap::tm_borders(lwd=2) +
tmap::tm_shape(localm) + 
  tmap::tm_facets(nrow = 1) + 
  tmap::tm_borders(lwd=0.5, alpha=0.4) +
  tmap::tm_fill(col = c("lsa_pib", "lsa_g"), style = "cat", palette = "Set1",
                title = "Local Moran's I",
                colorNA = "white", textNA = "not significant",) +
tmap::tm_layout(legend.position = c("left", "bottom"),
                  panel.labels=c("2002 GDP (per capita, BRL)", "2002-2011 growth rate (%)"))
```


## Proposal of a municipality-level growth model

Typical growth regressions, as motivated in the literature on convergence across countries, regress growth rates of countries or regions on their capital stock (usually GDP) at the initial period as well as a number of further determinants of growth [@barro1991economic]. Typically, these include information such as on population growth, human capital stock, sectoral structure and employment [@crespo2014determinants]. These variables likely exhibit spatial dependence, implying that the assumption of independence between observations - typically assumed in classical linear regressions - is violated. In fact, I demonstrated in the sections above that the variables so-far collected for my research are spatially autocorellated. Spatial econometric models explicitly consider spatial dependence. @lesage2008growth propose following Spatial Durbin Model (SDM) for growth regressions:

$$\boldsymbol{y} = \rho \boldsymbol{Wy} + \boldsymbol{X\beta} + \boldsymbol{WX \theta} + \boldsymbol{u}$$
In my case, the dependent variable $\boldsymbol{y}$ denotes an $n \times 1$ vector of regional economic growth rates for $n$ Brazilian municipalities. $\boldsymbol{X}$ is an $n \times k$ matrix of $k$ exogenous regional characteristics in the initial period. $\mathbf{W}$ denotes the so-called spatial weights or connectivity matrix, allowing for parsimonious treatment of spatial dependence [@anselin2013spatial]. It is an $n \times n$, non-negative, row-standardised matrix with $w_{ii} = 0$. Its elements are used to specify the spatial dependence structure among the observations, i.e. $w_{ij} > 0$ if region $j$ is in a neighbourhood relationship with region $i$ ($i, j = 1, \dots, n$). The $k \times 1$ vectors $\boldsymbol{\beta}$ and $\boldsymbol{\theta}$ correspond to $\boldsymbol{X}$ and $\boldsymbol{WX}$ respectively, and $\rho \in (-1, 1)$ captures the strength of spatial autocorrelation. The random error term $\boldsymbol{u}$ is assumed to be constant and normally distributed.

Note that the SDM collapses into altered forms of spatial model types if either $\lambda = 0$ or $\rho = 0$. The former is referred to as the spatial autoregressive model (SAR). The latter type represents the so-called spatial lag of X model (SLX). For the case of both parameters being zero, the model collapses to a classical linear model.

For the continued report, I will use this and that dependent and (partly logged) explanatory variables for this report, because it is about sketchiny the model and not about data mining. 

### Classical linear model

Note that while originally intended to use artificial data, I will actually use real data right away in a small and preliminary model.

```{r clm, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}

reg_data <- dplyr::left_join(
  dat_gdp %>% dplyr::select(code_mn, g_cap, pib_per_capita),
  dat_pop %>% dplyr::select(code_mn, g_pop) %>% sf::st_drop_geometry(), by = "code_mn") %>%
  dplyr::left_join(dat_sect %>% dplyr::select(code_mn, vab_agropecuaria_perc, vab_industria_perc) %>% sf::st_drop_geometry(), by = "code_mn")

reg_data <- reg_data %>% 
  dplyr::left_join(bra_mines %>% 
                     sf::st_drop_geometry() %>% 
                     dplyr::mutate(code_mn = as.character(code_mn)) %>%
                     dplyr::select(code_mn, mine_count), 
                   by = c("code_mn" = "code_mn")) %>% dplyr::select(-code_mn) %>%
  sf::st_drop_geometry() %>%
  dplyr::mutate(mine = ifelse(is.na(mine_count), 0, 1))

m <- g_cap ~ log(pib_per_capita) + g_pop + mine + vab_agropecuaria_perc + vab_industria_perc
m_ols <- lm(formula = m, data = reg_data); summary(m_ols)
```

We can explore the residuals. What we do not want is the residuals to have a spatial pattern.

```{r lmmorantest, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
spdep::lm.morantest(m_ols, listw=lwW, alternative="two.sided")
```

We find positive spatial autocorrelation in the residuals. Not too high, but still the residuals are systematically related. As this is a problem for statistical inference, we try to address this issue with a spatial regression approach.

### Spatial models

The `spatialreg` packages provides a number of types. I want to try 3: sar (global spatial model), slx (local spatial model), sdm (combines)

```{r sar, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
m_sar <- spatialreg::lagsarlm(formula = m, data = reg_data, listw = lwW); summary(m_sar)
```

```{r slx, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
m_slx <- spatialreg::lmSLX(formula = m, data = reg_data, listw = lwW); summary(m_slx)
```

```{r sdm, echo = TRUE, eval = TRUE, message=FALSE,  warning=FALSE}
m_sdm <- spatialreg::lagsarlm(formula = m, data = reg_data, listw = lwW, Durbin = TRUE); summary(m_sdm)
```

Note that one can employ an LM test for systematic model selection (source!), i.e. spdep::lm.LMtests()

Impacts


### Bayesian MCMC approaches for spatial econometric models

@lesage2009introduction introduce the estimation of spatial models applying Bayesian methodology. Central to this technique is to rely on *conditional distributions* involving data and estimated parameters in order to obtain the *posterior distributions* of single parameters. Instead of relying on a complicated analytical solution of these posterior distributions, they highlight the usefulness of Markov Chain Monte Carlo (MCMC) estimation approaches. The great benefit of approaching spatial econometric problems by the use of Bayesian estimation is that the MCMC sampling can be easily extended for specific model needs such as allowing for a heteroskedastic disturbance structure, model selection and model averaging, or modelling spatially autocorrelated cencored and binary dependent variables.

Let $D = \{y, X, W\}$ represent model data and $\theta$ denote the model parameters to be estimated. Applying Bayes rule, it follows that 

$$p(\theta|D) = \frac{p(D|\theta)p(\theta)}{p(D)}$$
The posterior distribution of $\theta$ thus is a compromise between *prior* information $p(\theta)$ and the *likelihood* $p(D|\theta)$, i.e. information coming from the sample data and the model. Simplifying this term by ignoring the data distribution $p(D)$ (it does not involve the parameters $\theta$), the posterior distribution of $\theta$ is a proportional product of $p(D|\theta)$ and $p(\theta)$. 

The likelihood of a SAR model, i.e. $y = (I-\rho W)^{-1} X\beta + u$, can be written as

$$p(D|\beta, \sigma, \rho) = (2\pi\sigma^2)^{-\frac{n}{2}} \ |A| \ exp\left(-\frac{1}{2\sigma^2}(Ay - X\beta)'(Ay - X\beta)\right)$$
where, for notation convenience, $A = I_n - \rho W$. This likelihood is then combined with prior distributions of the parameters in the model. @lesage2009introduction rely on a so-called *normal-inverse gamma prior* (NIG) for the parameters $\beta$ and $\sigma^2$, where $\beta$ follows a normal distribution conditional on an inverse gamma distribution for the parameter $\sigma^2$. While we have usually little intuition for $\beta$ and $\sigma^2$ and hence rely on fairly uninformative priors for these parameters, the case of $\rho$ is more interesting. From the row-standardisation of W and its corresponding eigenvalues, we know that $\rho \in (-1,1)$. Reasonable prior choices for $\rho$ would be a uniform distribution on the interval $(-1, 1)$ or, following @lesage2007beta, a $Beta(d, d)$ distribution that is centered on zero. Negative spatial dependence may further be of little interest for certain applications, motivating a prior where $\rho \in [0,1)$.

Instead of working out analytical/numerical integration solutions for this problem, the idea of MCMC sampling is to examine a large random sample from the posterior distribution. For $\beta$ and $\sigma^2$, @lesage2009introduction show that the conditional distributions under the NIG prior take known forms: $\beta$ comes from a multivariate normal with mean and variance obtained from combining data and prior information, and $\sigma^2$ follows an inverse gamma distribution with shape and scale parameters that are, again, computed from available information. As these are familiar conditional distriutions, it is possible to apply a sampling technique referred to as *Gibbs sampling*, where the respective parameters are sampled and updated treating the remaining parameters as known.

Yet, we do not always know the distributional form of conditional distributions, as is the case for the spatial parameter $\rho$. It takes the form
$$p(\rho|\beta, \sigma) \propto |I_n-\rho W| \ exp\left(-\frac{1}{2\sigma^2}(Ay - X\beta)'(Ay - X\beta)\right)$$
Therefore, we need an alternative sampling approach, such as the Metropolis-Hastings (M-H) algorithm. Meeting the notion of easily extendable, toolbox-style, Bayesian approaches, this procedure of sampling for $\rho$ is integrated as a separate step in the Gibbs sampling (*Metropolish within Gibbs*). The M-H sampling works as follows: In a first step, $\rho^*$, a candidate value for $\rho$, is generated from a *proposal distribution*. Second, this candidate value as well as the current value, which we label $\rho^c$, are used to evaluate the respective conditional likelihoods, in order to calculate an acceptance probability 
$$\psi_H(\rho^c, \rho^*) = min \left[ 1, \frac{p(\rho^*|\beta, \sigma)}{p(\rho^c|\beta, \sigma)} \right] $$
Finally, the proposed $\rho^*$ is accepted and becomes the new $\rho^c$ with probability $\psi_H(\rho^c, \rho^*)$ and otherwise we stay with the current value of $\rho^c$ for the next iteration. As a proposal distribution, @lesage2009introduction refer to a normal distribution along with a *tuned random walk procedure* suggested by @holloway2002bayesian, i.e. $\rho^* = \rho^c + c \cdot N(0,1)$, in order to let the sampler *move* over the entire conditional distribution. The *tuning* parameter $c$ is adjusted based on monitoring the acceptance rates, such as $c' = c/1.1$ whenever the acceptance rate falls below 40\% and $c' = c \cdot 1.1$ whenever it rises above 60\%. Moreover, we can make sure that $-1 < \rho < 1$ or any other restriction by using *rejection sampling*, i.e. rejecting values of $\rho$ outside the desired interval and drawing another proposal.

To provide a comprehensive overview, I here recall the MCMC sampling algorithm for the SAR model under the $NIG(c, T, a, b)$ prior for $\beta$ and $\sigma^2$ as summarised by @lesage2009introduction:

1. Sample $p(\beta|\sigma^2_{(0)}, \rho_{(0)})$ using the $N(c^*, \sigma_{(0)}T^*)$) distribution with mean and variance:
$$c^* = (X'X + T^{-1})^{-1}(X'(I_n - \rho_{(0)} W)y + T^{-1}c \\ T^* = (X'X + T^{-1})^{-1}$$
Label the sampled parameter vector $\beta_{(1)}$ and use this to replace the parameter vector $\beta_{(0)}$.
Note that we have to set the parameters $c$ and $T$ for the NIG prior. As we face high prior uncertainty, we can choose a rather uninformative prior by setting $c=0$ and $T = I_k \cdot 10^{10}$.

2. Sample $p(\sigma^2|\beta_{(1)}, \rho_{(0)})$, using an inverse gamma distribution $IG(a^*, b^*)$, where
$$a^* = a + n/2 \\ b^* = b + (Ay-X\beta_{(1)})'(Ay-X\beta_{(1)})/2 \\ A = I_n - \rho_{(0)} W$$
For a diffuse prior, we can assign $a = b = 0$.

3. Sample $p(\rho|\beta_{(1)}, \sigma_{(1)})$ using the M-H algorithm. Label this updated value $\rho_{(1)}$ and return to step 1.

This sequence of steps is repeated many times in order to obtain and - after some *burn-in period* - collect a lage number of draws. These allow for inference regarding the model parameters other than by the use of mean and standard deviation point estimates as known from frequentist approaches. In fact, we can construct the entire posterior distribution of the parameters from which one can easily derive means, medians, or credible intervals.

What is next is to code the sampling algorithms for the SAR, as well as for the SDM and SLX types of spatial models.

## References
